Benchmarking ORM используемых при создании Android-приложений
=============================================================

Привет, Хабр! Меня зовут Артем Добровинский и я Android-разработчик в FINCH.

Однажды, кутаясь в дыму утренней сигары, я копался в исходниках одной ORM для Android. Увидев там package под названием `benchmarks` сразу заглянул туда, и был удивлен тем, что все оценки выполнены с помощью `Log.d(System.currentTimeMillis())`. Я видел такое не в первый раз. Обрушившееся осознание того, что что-то надо менять, заставило отставить в сторону бокал с виски и сесть за клавиатуру.

### Почему написана эта статья
Ситуация с пониманием того, как мерять производительность кода в Android — печальная.   
Сколько не рассказывай про профайлеры, а разработчики так и продолжают кидать друг другу тайминги не понимая, что принимать это за хоть сколь корректное измерением можно только, если совсем не знать, как работает JVM.   
Т.е., необходимо в 2019 году быть уверенным, что JVM делает всё, что ты написал, и в том порядке, в котором ты написал. Нет ничего более далекого от истины.   
На самом деле, несчастная виртуальная машина отбивается от миллиарда безалаберных кнопкодавов, которые пишут целые программы, ни разу не напрягшись о том, как с этим кодом будет работать процессор. Эта битва длится уже не первый год, и в рукаве у неё миллион хитрейших оптимизаций, которые (если их игнорировать) превратят любое измерение производительности программы в потерю времени. 

Зачем стремиться к корректности проводимых оценок производительности?   
Во-первых (и это главная причина), нет лучшей почвы для холивара. Услышал мнение «А вот %FRAMEWORK% лучше», и сразу швырнул в центр комнаты распечатку со свежими бенчмарками — а то с полудня тихо, как в библиотеке.   
Во-вторых, если создать для измерений всех кейсов максимально схожие и идеальные условия — можно получить полезную информацию. Чтобы их создать надо знать, как это делать и на что обращать внимание, но это возможно — создать практически идеальную ситуацию и получить значимый результат. 

Если нужны доводы по поводу того, пользоваться ли для замера производительности сторонними фреймворками — всегда можно почитать [Алексея Шипилёва](https://shipilev.net/blog/2014/nanotrusting-nanotime/#_timers) и поразиться глубине проблемы. В статье по ссылке всё есть: и зачем нужен warmup перед проведением бенчмарка, почему `System.currentTimeMillis()` нельзя доверять вообще при подсчете прошедшего (elapsed) времени, и шутки за 300. Отличное чтиво. 

##### Почему я могу об этом рассказывать?   
Дело в том, что я всесторонне развитый разработчик: я не только владею Android SDK так, будто это мой pet-project, но еще где-то месяц писал код для бекенда.   
Когда я принес лиду свой первый микросервис на ревью, и там в `README` не было бенчмаркинга — он смотрел на меня с непониманием.   
Я запомнил это и больше никогда не повторял этой ошибки. Потому-что ушел через неделю.

Поехали.

### Что измеряем
В рамках кейса по бенчмаркингу баз данных под Android я решил померить скорость иницализации плюс записи/чтения для Paper, Hawk, Realm и Room.   
Да, я меряю в одном тесте NoSQL и реляционную БД — какой следующий вопрос?

### Чем измеряем
Казалось бы, если речь о JVM, то выбор очевиден — есть [покрытый славой](https://mvnrepository.com/tags/benchmark), [доведенный до совершенства](https://groups.google.com/d/msg/mechanical-sympathy/m4opvy4xq3U/7lY8x8SvHgwJ) и [безупречно задокументированный](http://hg.openjdk.java.net/code-tools/jmh/file/f2e982b7c51b/jmh-samples/src/main/java/org/openjdk/jmh/samples/) [JMH](https://openjdk.java.net/projects/code-tools/jmh/). Но нет, на нём не заведyтся инструментационные тесты для Android.   
Следом за ними идет [Calipher](https://github.com/google/caliper) от Google — с тем же результатом.    
Есть форк Calipher под называнием [Spanner](https://github.com/cmelchior/spanner) — который как много лет задеперкейчен и призывает пользоваться [Androidx Benchmark](https://developer.android.com/jetpack/androidx/releases/benchmark).   
Остановим внимание на последнем. Хотя бы потому, что у нас не осталось выбора.

Как и всё, что было добавлено в Jetpack, а не переосмыслено при переносе из Support Library, Androidx Benchmark выглядит и ведёт себя так, будто был написан за неделю-полторы в качестве тестового задания, и больше к нему никто никогда не притронется.   
Плюс, эта либа немного мимо — т.к., она больше для оценки UI-тестов. Но за неимением лучшего, можно работать и с ней. Это убережет нас хотя бы от [очевидных ошибок](https://android.googlesource.com/platform/frameworks/support/+/refs/heads/androidx-benchmark-release/benchmark/common/src/main/java/androidx/benchmark/Errors.kt), а также поможет с разогревом.
Для снижения смехотворности результатов я проведу все оценки 10 раз и вычислю средний показатель.

Все тесты будут прогоняться на Xiaomi A1.

### Подключение библиотеки в проект
По подключению Andoridx Benchmark в проект есть [отличная инструкция](https://developer.android.com/studio/profile/benchmark.md). Очень советую не полениться и подключить отдельный модуль для производства измерений. 

### Ход эксперимента
Все наши бенчмарки будут исполнятся в следующем порядке:
1. Сначала мы инициируем базу данных в теле теста.
2. Затем в блоке `benchmarkRule.scope.runWithTimingDisabled` генерим данные, которые скормим базе данных.
3. Замеряем производительность инициализации БД в отдельном методе. Для замера оборачиваем логику в замыкание `benchmarkRule.measureRepeated`.
4. Схожий блок подавления таймина с логикой очищения БД вставляем во второй метод; убеждаемся, что база данных пуста перед записью. 
5. Далее следует логика записи и чтения. Обязательно ицициализируем переменную с результатом чтения, чтобы JVM не удалил эту логику из исполнения, как неиспользуемую. 
6. Мы великолепны!

Код можно посмотреть [здесь](). Если лениво ходить, функция с замером для PaperDb выглядит так:
```kotlin
@Test
fun paperdbInsertReadTest() = benchmarkRule.measureRepeated {
    // чистим базу (это время не учитывается в оценку)
    benchmarkRule.scope.runWithTimingDisabled {
        Paper.book().destroy()
        if (Paper.book().allKeys.isNotEmpty()) throw RuntimeException()
    }
    // пишем и читаем
    repository.store(persons, { list -> Paper.book().write(KEY_CONTACTS, list) })
    val persons = repository.read { Paper.book().read<List<Person>>(KEY_CONTACTS, emptyList()) }
}
```
Бенчмарки для остальных ORM выглядят схожим образом.

#### Результаты
##### Инициализация
| название теста                            | mean          | 1          | 2          | 3          | 4          | 5          | 6          | 7          | 8          | 9          | 10         |
|-------------------------------------------|---------------|------------|------------|------------|------------|------------|------------|------------|------------|------------|------------|
| HawkBenchmarking.hawkInitTest             | 49 512        | 49282      | 50021      | 49119      | 50145      | 49970      | 50047      | 46649      | 50230      | 49863      | 49794      |
| PaperDbBenchmarking.paperdbInitTest       | 224           | 223        | 223        | 223        | 233        | 223        | 223        | 223        | 223        | 223        | 223        |
| RealmBenchmarking.realmInitTest           | 218           | 217        | 217        | 217        | 217        | 217        | 217        | 217        | 227        | 217        | 217        |
| RoomBenchmarking.roomInitTest             | 61 695.5      | 63450      | 59714      | 58527      | 59175      | 63544      | 62980      | 63252      | 59670      | 63868      | 62775      |

Победитель — Realm, на втором месте Paper. Чем занимается Room еще можно представить, что почти столько же времени делает Hawk — абсолютно непонятно.

##### Запись и чтение
| название теста                            | mean            | 1          | 2          | 3          | 4          | 5          | 6          | 7          | 8          | 9          | 10         |
|-------------------------------------------|-----------------|------------|------------|------------|------------|------------|------------|------------|------------|------------|------------|
| HawkBenchmarking.hawkInsertReadTest       | 278 736 469.2   | 278098654  | 283956846  | 276748308  | 282447384  | 272609500  | 284699653  | 271869770  | 278719693  | 278836115  | 279378769  |
| PaperDbBenchmarking.paperdbInsertReadTest | 173 519 957.3   | 172953347  | 174702000  | 169740846  | 174401192  | 173930037  | 174179616  | 173937460  | 173739115  | 176215038  | 171400922  |
| RealmBenchmarking.realmInsertReadTest     | 111 644 042.3   | 108501578  | 110616078  | 102056461  | 112946577  | 111701231  | 114922962  | 106198000  | 118742498  | 120888230  | 109866808  |
| RoomBenchmarking.roomInsertReadTest       | 1 863 499 483.3 | 1872503614 | 1837078614 | 1872482538 | 1827338460 | 1869147999 | 1857126229 | 1842427537 | 1870630652 | 1878862538 | 1907396652 |

Тут опять победитель Realm, но в этих результатах попахивает провалом.   
Разница в четыре раза между двумя самыми «медленными» базами данных и в шестнадцать раз между самой «быстрой» и самой «медленной» — очень подозрительна. Даже с учетом того, что разница держится стабильно.

### Заключение

Нет ни одной причины не измерять производительность своего кода. Особенно учитывая, что это возможно и в самых запущенных индустрией случаях (таких оценка инструментальных тестов под Android).   
Есть все причины привлекать для этого дела сторонние фреймворки (а не писать свой с таймингом и чирлидершами).    
У всех всё по-clean'у, у всех модуль с бизнес-логикой является java-модулем — подключить рядом модуль c jmh и проверять код на наличие бутылочных горлышек — работы на день. А пользы — на много лет вперед.

Happy coding!